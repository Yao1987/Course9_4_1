library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(R.utils)
library(ggplot2)
library(plyr)
library(dplyr)
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(url, "StormData.csv.bz2")
bunzip2("StormData.csv.bz2")
StormData <- read.csv("StormData.csv", sep = ",")
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x)
mu1=0.1471
x.*w
x*w
y=w*(x-mu1)^2
sum(y)
mu2=0.0025
mu3=1.077
mu4=0.300
y=sum(w*(x-mu2)^2)
y
y=sum(w*(x-mu3)^2)
y
y=sum(w*(x-mu4)^2)
y
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
LC=lm(y~ 0+x)
LC
data("mtcars")
Data=data("mtcars")
str(Data)
Data=data(mtcars)
str(Data)
data('mtcars')
D<-data('mtcars')
str(D)
summary('mtcars')
str('mtcars')
str(mtcars)
LC=lm(mtcars$mpg~mtcars$wt)
LC
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xb=(x-mean(x))/sd(x)
xb
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
LC=lm(y~x)
LC
LC=lm(x~y)
LC
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y<-zeros(length(x))
y<-zero(length(x))
y<-0*x
y
LC=lm(y~offset(0*x))
LC
LC=lm(x~1)
LC
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
b1 <- cor(x,y)*sd(y)/sd(x)
b0 <- mean(y) - b1 * mean(x)
b0
x
x-mean(x)
I(x-mean(x))
library(UsingR)
install.packages("UsingR")
data(diamond)
library(UsingR)
install.packages("UsingR")
install.packages("C:/Users/Administrator/Downloads/UsingR_2.0-6.tar.gz", repos = NULL, type = "source")
library(UsingR)
install.packages("usingR")
install.packages("UsingR")
install.packages("C:/Users/Administrator/Downloads/UsingR_2.0-6.zip", repos = NULL, type = "win.binary")
library(UsingR)
install.packages("HistData")
data(diamond)
?I
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
AppliedPredictiveModeling
install.packages("AppliedPredictiveModeling")
install.packages("C:/Users/Administrator/Downloads/AppliedPredictiveModeling_1.1-7.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/Administrator/Downloads/AppliedPredictiveModeling_1.1-7.zip", repos = NULL, type = "win.binary")
AppliedPredictiveModeling
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
install.packages("devtools")
options(repos="https://CRAN.R-project.org")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("caret")
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. (The outcome class is contained in a factor variable called Class with levels "PS" for poorly segmented and "WS" for well segmented.)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
data(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
library(caret)
library(ggplot2)
library(lattice)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
install.packages("e1071")
str(segmentationOriginal)
colnames(segmentationOriginal)
segmentationOriginal$Case
segmentationOriginal$Class
?rpart
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
modolive
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(rpart.plot)
fancyRpartPlot(modolive)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modolive)
library(ggplot2)
library(rpart.plot)
fancyRpartPlot(modolive)
library(caret)
library(rpart.plot)
fancyRpartPlot(modolive)
library(AppliedPredictiveModeling)
library(rpart.plot)
fancyRpartPlot(modolive)
library(hplot)
install.packages("hplot")
library(rpart)
library(rpart.plot)
fancyRpartPlot(modolive)
library(rpart.plot)
rpart.plot(modolive)
library(RColorBrewer)
library(rattle)
install.packages("rattle")
modolive <- train(Area ~ ., method = "rpart", data = olive)
library(pgmm)
data(olive)
olive = olive[, -1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
rpart.plot(modolive$results)
rpart.plot(modolive)
str(modolive)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret))
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. (The outcome class is contained in a factor variable called Class with levels "PS" for poorly segmented and "WS" for well segmented.)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
modolive$finalModel
rpart.plot(modolive$finalModel)
head(olive#Area)
%
head(olive$Area)
str(olive$Area)
summary(olive$Area)
qplot(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomForest")
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(lubricate)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
?confusionMatrix
install.packages("lubridate")
install.packages("lubridate")
options(repos="https://CRAN.R-project.org")
install.packages("lubridate")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
mod_rf=train(y,data=vowel.train,method='rf')
library(ElemStatLearn)
mod_rf=train(y,data=vowel.train,method='rf')
mod_rf=train(y~.,data=vowel.train,method='rf')
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
?train
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
?predict
install.packages("caret")
install.packages("AppliedPredictiveModeling")
mod_rf=train(y~.,data=vowel.train,method='rf')
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
mod_rf=train(y~.,data=vowel.train,method='rf')
install.packages(c("BH", "class", "clipr", "codetools", "colorspace", "curl", "data.table", "evaluate", "foreign", "httr", "jsonlite", "lattice", "MASS", "Matrix", "mgcv", "modelr", "openssl", "pillar", "purrr", "Rcpp", "readr", "readxl", "rlang", "stringi", "stringr", "survival", "tibble", "tinytex"))
mod_rf=train(y~.,data=vowel.train,method='rf')
library(caret)
library(lattice)
library(ggplot2)
library(caret)
mod_rf=train(y~.,data=vowel.train,method='rf')
mod_gbm=train(y~.,data=vowel.train,method='gbm')
?predict
pred_rf=predict(mod_rf,vowel.train)
pred_gbm=predict(mod_gbm,vowel.train)
sum(pref_rf$y==vowel.test$y)/sum(vowel.test$y)
sum(pref_rf$y==vowel.test$y)/length(vowel.test$y)
sum(pred_rf$y==vowel.test$y)/length(vowel.test$y)
sum(pred_rf==vowel.test$y)/length(vowel.test$y)
sum(pred_rf==vowel.test$y)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
sum(pred_rf==vowel.test$y)/length(vowel.test$y)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf=train(diagnosis~.,inTrain,method='rf')
mod_rf=train(diagnosis~.,data=inTrain,method='rf')
mod_rf=train(diagnosis~.,inTrain,method='rf')
str(inTrain)
mod_rf=train(diagnosis~.,data=training,method='rf')
mod_gbm=train(diagnosis~.,data=training,method='gbm')
mod_ida=train(diagnosis~.,data=training,method='ida')
mod_lda=train(diagnosis~.,data=training,method='lda')
pred_rf=predict(mod_rf,training)
pred_gbm=predict(mod_gbm,training)
pred_lda=predict(mod_lda,training)
comb=data.frame(pred_rf,pred_gbm,pred_lda)
comb=data.frame(pred_rf,pred_gbm,pred_lda,diagnosis=testing$diagnosis)
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
library(leaflet)
Work_adres=c(50.876433, 4.700745)
Home_adres=c(50.885785, 4.309687)
Long=c(50.876433,50.885785)
Latt=c(4.700745,4.309687)
Work_imag="http://www.justthoughtyoushouldknow.org/wp-content/uploads/2014/08/Work_life_balance_rat_race.png"
Home_imag="https://www.shutterstock.com/zh/image-vector/black-white-outlined-dog-bone-cartoon-676567417?src=ugaK_0STtigSExSLfg9WnQ-1-61"
Work_icon<-makeIcon(Work_imag,iconWidth=31,iconHeight = 31,iconAnchorX = 16,iconAnchorY = 16)
Home_icon<-makeIcon(Home_imag,iconWidth=31,iconHeight = 31,iconAnchorX = 16,iconAnchorY = 16)
Icon=c(Work_icon,Home_icon)
Pop=c("Work address","Home address")
Location<-data.frame(lng=c(Work_adres[1],Home_adres[1]),lat=c(Work_adres[2],Home_adres[2]))
Location
Location %>% leaflet() %>% addTiles() %>% addMarkers(lng=~lng,lat=~lat)
Location %>% leaflet() %>% addTiles() %>% addMarkers(lng=Location $lng,lat=Location $lat)
Location %>% leaflet() %>% addTiles()
Location %>% leaflet() %>% addTiles() %>% addMarkers(Location $lng,Location $lat)
Location %>% leaflet() %>% addTiles()
TsunamiC <- data.frame(name = c("Indonesia", "Sri_Lanka", "India", "Thailand",
"Somalia", "Maldives", "Malaysia", "Myanmar",
"Tanzania", "Seychelles", "Bangladesh",
"South_Africa", "Yemen", "Kenya"),
casulties = c("126900", "31000", "10700", "5400", "300", "80",
"70", "60", "10", "2", "2", "2", "2", "1"),
lat = c(5.548290, 6.053519, 10.765608, 7.951933, 9.498580,
4.175496, 5.407773, 16.999953, -6.779853, -4.686122,
22.608306, -32.371843, 15.853031, -2.560335),
lng = c(95.323756, 80.220977, 79.842389, 98.338088, 50.810526,
73.509347, 100.262775, 96.989365, 38.638916,
55.521126, 90.362549, 27.048340, 51.284180, 39.924316)
)
## Link to URL
Epi <- c("<a href= 'https://en.wikipedia.org/wiki/2004_Indian_Ocean_earthquake_and_tsunami' >Epicentre</a>")
## Different markers
ic <- awesomeIcons(icon = "ios-close", iconColor = "black", library = "ion",
markerColor = "red")
TsunamiC %>%
leaflet() %>%
addProviderTiles(providers$Esri.WorldStreetMap) %>%
addMarkers(lng = ~lng, lat = ~lat, label = ~htmlEscape(casulties),
clusterOptions = markerClusterOptions(), group = "Casulties") %>%
addAwesomeMarkers(lng = 95.854, lat = 3.316, icon = ic, popup = Epi,
group = "Epicentre") %>%
addLayersControl(overlayGroups = c("Casulties", "Epicentre"),
options = layersControlOptions(collapsed = FALSE))
install.packages("htmltools")
install.packages("htmlwidgets")
library(htmltools)
library(htmlwidgets)
TsunamiC %>%
leaflet() %>%
addProviderTiles(providers$Esri.WorldStreetMap) %>%
addMarkers(lng = ~lng, lat = ~lat, label = ~htmlEscape(casulties),
clusterOptions = markerClusterOptions(), group = "Casulties") %>%
addAwesomeMarkers(lng = 95.854, lat = 3.316, icon = ic, popup = Epi,
group = "Epicentre") %>%
addLayersControl(overlayGroups = c("Casulties", "Epicentre"),
options = layersControlOptions(collapsed = FALSE))
TsunamiC %>% leaflet()
?mtcars
mtcars
load(mtcars)
library(datasets)
load("mtcars")
load(mtcars)
data(mtcars)
str(mtcars)
library(ggplot2)
?qplot
library(ggplot2)
data(mtcars)
ff=lm(cyl~hp,data=mtcars)
ff[1]
ff
qplot(cyl,hp,data=mtcars)
summary(ff)
coefficients(ff)
cf=coefficients(ff)
cf[1]
cf[2]
?geom_line
geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]))
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]))
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),'red')
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),1)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),color=1)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),color=3)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),color=2)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),color=5)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),color=2)
ff=lm(hp~cyl,data=mtcars)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]))
cf
ff=lm(hp~cyl,data=mtcars)
cf=coefficients(ff)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]))
library(ggplot2)
data(mtcars)
ff=lm(hp~cyl,data=mtcars)
cf=coefficients(ff)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
data(mtcars)
library(ggplot2)
data(mtcars)
ff=lm(hp~cyl,data=mtcars)
cf=coefficients(ff)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
library(ggplot2)
data(mtcars)
ff=lm(hp~cyl,data=mtcars)
cf=coefficients(ff)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
qplot(cyl,hp,data=mtcars)
qplot(aes(x=mtcars$cyl,y=mtcars$hp))+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
qplot(aes(x=mtcars$cyl,y=mtcars$hp),data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
qplot(aes(x=mtcars$cyl,y=mtcars$hp),data=mtcars)
qplot
qplot(mtcars,aes(x=cyl,y=hp))+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
ggplot(mtcars,aes(x=cyl,y=hp))+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
ggplot(mtcars,aes(x=cyl,y=hp))
?ggplot
qplot(cyl~hp,data=mtcars)
qplot(cyl,hp,data=mtcars)
qplot(cyl,hp,data=mtcars)+geom_line(NULL,aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
qplot(cyl,hp,data=mtcars)+geom_line(data=mtcars,aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
qplot(cyl,hp,data=mtcars)
+geom_line(data=mtcars,aes(x=cyl,y=cyl*cf[2]+cf[1]),2)
?geom_line
qplot(cyl,hp,data=mtcars)+geom_line(aes(x=cyl,y=cyl*cf[2]+cf[1]),color=2)
str(mtcars)
shiny::runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
shiny::runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1/Course9_4_1')
runApp('~/GitHub/Course9_4_1')
# Chunk 1
summary(cars)
# Chunk 2
plot(cars)
setwd("~/GitHub/Course9_4_1")
jpeg("AppAppearance.JPG")
jj=jpeg("AppAppearance.JPG")
